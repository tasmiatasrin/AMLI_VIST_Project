{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea16a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# open JSON file\n",
    "f = open('train.story-in-sequence.json')\n",
    "\n",
    "# returns JSON object as a dictionary\n",
    "train_data = json.load(f)\n",
    "\n",
    "# close file\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at train_data\n",
    "# annotations holds all the info\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1aca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data['annotations'])) # all the images and sentences\n",
    "print(len(train_data['annotations'])//5) # all the story_ids\n",
    "\n",
    "train_data['annotations'][0] # train_data of image-sentence pair, 5 pairs make a story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54275d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might have to run this line to be able to run the following lines\n",
    "# removes train_data rate limit\n",
    "\n",
    "# ! jupyter notebook --NotebookApp.iopub_train_data_rate_limit=1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36984aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get all the unique story ids\n",
    "story_ids = []\n",
    "\n",
    "for i in range(len(train_data['annotations'])):\n",
    "    story_id = train_data['annotations'][i][0]['story_id'] # grab the story id\n",
    "    \n",
    "    if story_id not in story_ids: # only unique ids\n",
    "      story_ids.append(story_id)\n",
    "    \n",
    "      # loading print\n",
    "      if len(story_ids)%1000 == 0:\n",
    "        print(len(story_ids))\n",
    "\n",
    "print(f'Finished! Length: {len(story_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# five sentences into their own list\n",
    "\n",
    "sentences = []\n",
    "five_sentences = []\n",
    "\n",
    "new_len = 0 # used for printing\n",
    "\n",
    "for i in range(len(train_data['annotations'])):\n",
    "    one_sentence = train_data['annotations'][i][0]['original_text'] # grab the sentence\n",
    "\n",
    "    # remove the space after each sentence\n",
    "    if one_sentence[-1] == ' ':\n",
    "      one_sentence = one_sentence[:-1]\n",
    "\n",
    "    # place the sentences into list\n",
    "    sentences.append(one_sentence)\n",
    "\n",
    "    # place the set of 5 sentences\n",
    "    if (i+1)%5 == 0:\n",
    "      five_sentences.append(sentences)\n",
    "      sentences = []\n",
    "\n",
    "    # loading print\n",
    "    old_len = len(five_sentences)\n",
    "    if len(five_sentences)%10000 == 0:\n",
    "        if new_len != old_len:\n",
    "            new_len = old_len\n",
    "        print(len(five_sentences))\n",
    "        \n",
    "print(f'Finished! Length: {len(five_sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb344bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image_ids\n",
    "\n",
    "images = []\n",
    "five_images = []\n",
    "\n",
    "new_len = 0 # used for printing\n",
    "\n",
    "for i in range(len(train_data['annotations'])):\n",
    "    one_image = train_data['annotations'][i][0]['photo_flickr_id'] # grab the image id\n",
    "    \n",
    "    images.append(one_image)\n",
    "\n",
    "    # place these five photos into list\n",
    "    if (i+1)%5 == 0:\n",
    "      five_images.append(images)\n",
    "      images = []\n",
    "        \n",
    "    # loading print\n",
    "      old_len = len(five_images)\n",
    "    if len(five_images)%10000 == 0:\n",
    "        if new_len != old_len:\n",
    "            new_len = old_len\n",
    "        print(len(five_images))\n",
    "        \n",
    "print(f'Finished! Length: {len(five_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# story dictionary\n",
    "\n",
    "dictionary = {\n",
    "    'stories' : story_ids,\n",
    "    'sentences' : five_sentences,\n",
    "    'images'    : five_images,\n",
    "}\n",
    "\n",
    "# first story  [0]\n",
    "# second story [1]\n",
    "#      .        .\n",
    "#      .        .\n",
    "#      .        .\n",
    "# nth story    [n]\n",
    "\n",
    "print(dictionary['stories'][0])\n",
    "print(dictionary['sentences'][0])\n",
    "print(dictionary['images'][0])\n",
    "\n",
    "# first story matches up\n",
    "\n",
    "train_data['annotations'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of the folder that contains the images\n",
    "import os\n",
    "\n",
    "! pwd\n",
    "\n",
    "home_dir = '/Users/javi/Desktop/AMLI/Capstone/1_story_dictionary_and_pickles/'\n",
    "\n",
    "! ls\n",
    "\n",
    "image_dir = '/Users/javi/Desktop/AMLI/Capstone/1_story_dictionary_and_pickles/images/train'\n",
    "\n",
    "os.chdir(image_dir)\n",
    "\n",
    "! pwd\n",
    "\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb012f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_split1_dictionary\n",
    "# only grab the story_ids of the images we have\n",
    "\n",
    "new_len = 0 # used for printing\n",
    "tsplit1_ids = []\n",
    "for image in os.listdir(image_dir): # grab each image from image directory\n",
    "    for i in range(len(dictionary['images'])): \n",
    "        story_id = dictionary['stories'][i] # story_id\n",
    "        image_list = dictionary['images'][i] # set of 5 images\n",
    "        print\n",
    "#     for story_id in dictionary['stories']: # grab each story id\n",
    "#         for image_list in dictionary['images']: # grab a set of 5 images\n",
    "#             for image_id in image_list: # grab just one image\n",
    "#             print(image[:-4], image_list)\n",
    "            \n",
    "        if image[:-4] in image_list: # ignores .jpg or .png\n",
    "            if story_id not in tsplit1_ids: # for no duplicate story_ids\n",
    "                tsplit1_ids.append(story_id)\n",
    "                \n",
    "                old_len = len(tsplit1_ids)\n",
    "            if len(tsplit1_ids)%500 == 0: # loading print\n",
    "                if new_len != old_len:\n",
    "                    new_len = old_len\n",
    "                    print(len(tsplit1_ids))\n",
    "                        \n",
    "print(f'Finished! Length: {len(tsplit1_ids)}')\n",
    "\n",
    "# change back to home dir\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb66a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make shortened dictionary\n",
    "\n",
    "tsplit1_sent = []\n",
    "tsplit1_imgs = []\n",
    "\n",
    "for ids in tsplit1_ids:\n",
    "    for i in range(len(dictionary['stories'])):\n",
    "        if ids == dictionary['stories'][i]:\n",
    "            tsplit1_sent.append(dictionary['sentences'][i]) # append the sentences\n",
    "            tsplit1_imgs.append(dictionary['images'][i]) # append the images\n",
    "\n",
    "# the lengths should match the one above\n",
    "print(len(tsplit1_sent), len(tsplit1_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719931a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tsplit1_ids[0], tsplit1_sent[0], tsplit1_imgs[0])\n",
    "\n",
    "# verify everything is correct\n",
    "count = 0\n",
    "for i in range(len(train_data['annotations'])):\n",
    "    story = train_data['annotations'][i][0]\n",
    "    if story['story_id'] == tsplit1_ids[0]:\n",
    "        count+=1\n",
    "        print(train_data['annotations'][i])\n",
    "        if count == 5:\n",
    "            break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3500dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e410b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into JSON file\n",
    "dictionary = {}\n",
    "\n",
    "for i in range(len(tsplit1_ids)):\n",
    "  dictionary[tsplit1_ids[i]] = {\n",
    "      'sentences' : tsplit1_sent[i],\n",
    "      'images'    : tsplit1_imgs[i]\n",
    "  }\n",
    "\n",
    "json_dict = dictionary\n",
    "\n",
    "with open(\"tsplit1_dictionary.json\", \"a\") as outfile: \n",
    "  json.dump(json_dict, outfile)\n",
    "\n",
    "# open JSON file\n",
    "f = open('tsplit1_dictionary.json')\n",
    "\n",
    "# returns JSON object as a dictionary\n",
    "data = json.load(f)\n",
    "    \n",
    "# # close file\n",
    "f.close\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything looks good\n",
    "data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
